{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langgraph langsmith"
      ],
      "metadata": {
        "id": "o-DYdfSitqJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UztHEp39tKHI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import operator\n",
        "from langsmith import traceable\n",
        "from langsmith.wrappers import wrap_openai\n",
        "from typing import Annotated, Literal, TypedDict\n",
        "from langgraph.graph import StateGraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ['LANGSMITH_API_KEY'] =  userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGSMITH_PROJECT'] = \"langchain-academy\"\n",
        "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\""
      ],
      "metadata": {
        "id": "Ymw1nepwuRym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[list, operator.add]\n",
        "\n",
        "tool_schema = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"search\",\n",
        "        \"description\": \"Call to surf the web.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\"query\": {\"type\": \"string\"}},\n",
        "            \"required\": [\"query\"],\n",
        "        },\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "WyMu76UJt7JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decorating the tool function will automatically trace it with the correct context\n",
        "@traceable(run_type=\"tool\", name=\"Search Tool\")\n",
        "def search(query: str):\n",
        "    \"\"\"Call to surf the web.\"\"\"\n",
        "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
        "        return \"It's 60 degrees and foggy.\"\n",
        "    return \"It's 90 degrees and sunny.\"\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "def call_tools(state):\n",
        "    function_name_to_function = {\"search\": search}\n",
        "    messages = state[\"messages\"]\n",
        "    tool_call = messages[-1][\"tool_calls\"][0]\n",
        "    function_name = tool_call[\"function\"][\"name\"]\n",
        "    function_arguments = tool_call[\"function\"][\"arguments\"]\n",
        "    arguments = json.loads(function_arguments)\n",
        "    function_response = function_name_to_function[function_name](**arguments)\n",
        "    tool_message = {\n",
        "        \"tool_call_id\": tool_call[\"id\"],\n",
        "        \"role\": \"tool\",\n",
        "        \"name\": function_name,\n",
        "        \"content\": function_response,\n",
        "    }\n",
        "    return {\"messages\": [tool_message]}\n",
        "\n",
        "wrapped_client = wrap_openai(openai.Client())\n",
        "\n",
        "def should_continue(state: State) -> Literal[\"tools\", \"__end__\"]:\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message[\"tool_calls\"]:\n",
        "        return \"tools\"\n",
        "    return \"__end__\"\n",
        "\n",
        "def call_model(state: State):\n",
        "    messages = state[\"messages\"]\n",
        "    # Calling the wrapped client will automatically infer the correct tracing context\n",
        "    response = wrapped_client.chat.completions.create(\n",
        "        messages=messages, model=\"gpt-4o-mini\", tools=[tool_schema]\n",
        "    )\n",
        "    raw_tool_calls = response.choices[0].message.tool_calls\n",
        "    tool_calls = [tool_call.to_dict() for tool_call in raw_tool_calls] if raw_tool_calls else []\n",
        "    response_message = {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": response.choices[0].message.content,\n",
        "        \"tool_calls\": tool_calls,\n",
        "    }\n",
        "    return {\"messages\": [response_message]}\n"
      ],
      "metadata": {
        "id": "DWrY8YMftU8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Yn56sD0tU5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"tools\", call_tools)\n",
        "workflow.add_edge(\"__start__\", \"agent\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        ")\n",
        "workflow.add_edge(\"tools\", 'agent')\n",
        "\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "J2I_gq6jtUri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_state = app.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
        ")"
      ],
      "metadata": {
        "id": "7l6d4qCXtUkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "final_state[\"messages\"][-1][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KllI-gsTteab",
        "outputId": "0a31d76c-449d-44c3-f4b2-e22701ea6f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in San Francisco is 60 degrees and foggy.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
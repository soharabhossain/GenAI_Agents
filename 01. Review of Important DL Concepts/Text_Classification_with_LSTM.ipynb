{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Text_Classification_with_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmpxJshjSK_v"
      },
      "source": [
        "# IMDB Movie Reviews - Sentiment Analysis\n",
        "\n",
        "This is a Binary Classification task.\n",
        "Analyze the written text reviews to find out whether a review is of type positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch_owWMDtSXN"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN42JKceLqav"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txJUiywytnC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4171a716-4db4-41d7-fa99-e80fde1392cc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7J54TBjtVch"
      },
      "source": [
        "## Load IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofrjW5ABRdlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4110c1-3013-4926-e47f-8780d3fd8cb3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdb_labelled.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZECbZWVLqbX"
      },
      "source": [
        "file=\"imdb_labelled.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvqTDTALqb4"
      },
      "source": [
        "imdb = pd.read_csv(file,sep='\\t',header=None,names=['review','sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVBHCEGJta9g"
      },
      "source": [
        "## Split into Training and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4cH3owLqce"
      },
      "source": [
        "imdb_train, imdb_test = train_test_split(imdb, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cMDS4o2Lqcy"
      },
      "source": [
        "x_train = imdb_train['review']\n",
        "y_train = imdb_train['sentiment']\n",
        "x_test = imdb_test['review']\n",
        "y_test = imdb_test['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4r6wgN6wBio"
      },
      "source": [
        "### Length of the Reviews in terms of the number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35IY65uDLqdB"
      },
      "source": [
        "sent_lens=[]\n",
        "for sent in imdb_train['review']:\n",
        "    sent_lens.append(len(word_tokenize(sent)))      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkBQSuDULqdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4189032-cb20-4606-99ab-4434ddc3c555"
      },
      "source": [
        "max(sent_lens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luj8A8_Uvws-"
      },
      "source": [
        "### Most Frequent Review Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRHsOdScLqdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4958b1c-2ebb-48a4-af08-c5e0b48a6e95"
      },
      "source": [
        "np.quantile(sent_lens,0.95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkL8bb7ft2zP"
      },
      "source": [
        "#### We can see that 95% review text are of lengths less than or equal to 40. \n",
        "\n",
        "### We'll keep the max length to 40 -- from each review (text paragraph) we will take the first 40 words and ingore the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-huuAoULqeE"
      },
      "source": [
        "# Set the maximum number of words in a given review\n",
        "max_len = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaGFesISwWWN"
      },
      "source": [
        "### Tokenize the Words from a Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gmr1SJwRxi"
      },
      "source": [
        "# Tokenize the words\n",
        "tok = Tokenizer(char_level=False, split=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhQimFPOwj81"
      },
      "source": [
        "#### Get a Token Index for Every Word in the current Vocabulary\n",
        "\n",
        "#### Fit the Tokenizer object with the training data. \n",
        "\n",
        "After this, the tokenizer knows the total number of unique words in the vocabulary (training set). A dictionary of all the unique words is formed. This is called the vocabulary. Every work is assignd a unique numeric code/index. This information is kept as a dictionary. A dictionary where numeric indices are the keys and the individual words are the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttpxeF65wjJd"
      },
      "source": [
        "tok.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnhYWoaBwtft"
      },
      "source": [
        "#### Check the Words and the corresponding Numeric Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1SbKmzwLqeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722b3932-5192-4e8e-aaa8-2cc70415a76b"
      },
      "source": [
        "# A distionary where numeric indices are the keys and the individual words are the values\n",
        "tok.index_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'the',\n",
              " 2: 'a',\n",
              " 3: 'and',\n",
              " 4: 'of',\n",
              " 5: 'is',\n",
              " 6: 'this',\n",
              " 7: 'it',\n",
              " 8: 'i',\n",
              " 9: 'to',\n",
              " 10: 'was',\n",
              " 11: 'movie',\n",
              " 12: 'in',\n",
              " 13: 'film',\n",
              " 14: 'that',\n",
              " 15: '1',\n",
              " 16: '0',\n",
              " 17: 'but',\n",
              " 18: 'for',\n",
              " 19: 'as',\n",
              " 20: 'with',\n",
              " 21: 'are',\n",
              " 22: 'on',\n",
              " 23: 'not',\n",
              " 24: 'you',\n",
              " 25: 'one',\n",
              " 26: 'very',\n",
              " 27: 'bad',\n",
              " 28: 'just',\n",
              " 29: 'so',\n",
              " 30: 'good',\n",
              " 31: 'all',\n",
              " 32: 'an',\n",
              " 33: \"it's\",\n",
              " 34: 'there',\n",
              " 35: 'be',\n",
              " 36: 'by',\n",
              " 37: 'about',\n",
              " 38: 'at',\n",
              " 39: 'if',\n",
              " 40: 'out',\n",
              " 41: 'great',\n",
              " 42: 'his',\n",
              " 43: 'from',\n",
              " 44: 'like',\n",
              " 45: 'have',\n",
              " 46: 'time',\n",
              " 47: 'were',\n",
              " 48: 'well',\n",
              " 49: 'has',\n",
              " 50: 'even',\n",
              " 51: 'really',\n",
              " 52: 'my',\n",
              " 53: 'or',\n",
              " 54: 'who',\n",
              " 55: 'acting',\n",
              " 56: 'he',\n",
              " 57: 'when',\n",
              " 58: 'most',\n",
              " 59: 'see',\n",
              " 60: 'how',\n",
              " 61: 'more',\n",
              " 62: 'characters',\n",
              " 63: 'would',\n",
              " 64: 'no',\n",
              " 65: 'only',\n",
              " 66: 'ever',\n",
              " 67: 'made',\n",
              " 68: 'also',\n",
              " 69: 'best',\n",
              " 70: '10',\n",
              " 71: 'plot',\n",
              " 72: 'some',\n",
              " 73: 'your',\n",
              " 74: 'do',\n",
              " 75: 'its',\n",
              " 76: 'character',\n",
              " 77: 'real',\n",
              " 78: 'because',\n",
              " 79: 'love',\n",
              " 80: \"didn't\",\n",
              " 81: 'movies',\n",
              " 82: 'can',\n",
              " 83: \"don't\",\n",
              " 84: 'other',\n",
              " 85: 'which',\n",
              " 86: 'they',\n",
              " 87: 'story',\n",
              " 88: 'way',\n",
              " 89: 'films',\n",
              " 90: 'actors',\n",
              " 91: 'think',\n",
              " 92: 'much',\n",
              " 93: 'seen',\n",
              " 94: 'too',\n",
              " 95: 'her',\n",
              " 96: 'me',\n",
              " 97: 'every',\n",
              " 98: 'script',\n",
              " 99: 'watching',\n",
              " 100: 'than',\n",
              " 101: 'had',\n",
              " 102: 'up',\n",
              " 103: 'scenes',\n",
              " 104: 'over',\n",
              " 105: 'wonderful',\n",
              " 106: 'show',\n",
              " 107: 'what',\n",
              " 108: 'could',\n",
              " 109: 'little',\n",
              " 110: 'watch',\n",
              " 111: 'will',\n",
              " 112: 'funny',\n",
              " 113: 'work',\n",
              " 114: 'any',\n",
              " 115: 'worth',\n",
              " 116: 'make',\n",
              " 117: 'here',\n",
              " 118: 'man',\n",
              " 119: 'art',\n",
              " 120: 'music',\n",
              " 121: 'into',\n",
              " 122: 'cast',\n",
              " 123: 'many',\n",
              " 124: 'better',\n",
              " 125: 'screen',\n",
              " 126: 'totally',\n",
              " 127: 'go',\n",
              " 128: 'both',\n",
              " 129: 'their',\n",
              " 130: 'never',\n",
              " 131: 'anyone',\n",
              " 132: 'say',\n",
              " 133: 'look',\n",
              " 134: 'nothing',\n",
              " 135: 'everything',\n",
              " 136: 'after',\n",
              " 137: 'again',\n",
              " 138: 'thought',\n",
              " 139: 'line',\n",
              " 140: 'waste',\n",
              " 141: 'get',\n",
              " 142: 'life',\n",
              " 143: 'excellent',\n",
              " 144: 'dialogue',\n",
              " 145: 'scene',\n",
              " 146: 'still',\n",
              " 147: 'such',\n",
              " 148: 'being',\n",
              " 149: \"doesn't\",\n",
              " 150: 'writing',\n",
              " 151: 'people',\n",
              " 152: 'performance',\n",
              " 153: 'going',\n",
              " 154: 'awful',\n",
              " 155: 'things',\n",
              " 156: 'years',\n",
              " 157: 'right',\n",
              " 158: 'recommend',\n",
              " 159: 'know',\n",
              " 160: 'director',\n",
              " 161: \"i'm\",\n",
              " 162: 'truly',\n",
              " 163: 'off',\n",
              " 164: 'she',\n",
              " 165: 'cinematography',\n",
              " 166: 'saw',\n",
              " 167: 'enough',\n",
              " 168: 'been',\n",
              " 169: 'stupid',\n",
              " 170: 'them',\n",
              " 171: 'liked',\n",
              " 172: 'however',\n",
              " 173: 'though',\n",
              " 174: 'simply',\n",
              " 175: 'give',\n",
              " 176: 'ending',\n",
              " 177: 'thing',\n",
              " 178: 'feeling',\n",
              " 179: 'enjoyed',\n",
              " 180: 'beautiful',\n",
              " 181: \"i've\",\n",
              " 182: 'terrible',\n",
              " 183: \"can't\",\n",
              " 184: 'should',\n",
              " 185: 'am',\n",
              " 186: 'actually',\n",
              " 187: 'lot',\n",
              " 188: 'makes',\n",
              " 189: 'through',\n",
              " 190: 'does',\n",
              " 191: 'game',\n",
              " 192: 'camera',\n",
              " 193: 'worst',\n",
              " 194: 'predictable',\n",
              " 195: 'whole',\n",
              " 196: 'done',\n",
              " 197: \"that's\",\n",
              " 198: 'definitely',\n",
              " 199: 'loved',\n",
              " 200: 'job',\n",
              " 201: 'part',\n",
              " 202: 'pretty',\n",
              " 203: 'quite',\n",
              " 204: 'drama',\n",
              " 205: 'highly',\n",
              " 206: 'black',\n",
              " 207: 'between',\n",
              " 208: 'found',\n",
              " 209: 'play',\n",
              " 210: 'two',\n",
              " 211: 'understand',\n",
              " 212: 'these',\n",
              " 213: 'kind',\n",
              " 214: 'first',\n",
              " 215: 'interesting',\n",
              " 216: 'those',\n",
              " 217: 'find',\n",
              " 218: 'another',\n",
              " 219: 'series',\n",
              " 220: 'kids',\n",
              " 221: 'we',\n",
              " 222: 'written',\n",
              " 223: 'did',\n",
              " 224: 'worse',\n",
              " 225: 'played',\n",
              " 226: 'watched',\n",
              " 227: 'least',\n",
              " 228: 'sucked',\n",
              " 229: 'old',\n",
              " 230: 'actor',\n",
              " 231: 'playing',\n",
              " 232: 'horror',\n",
              " 233: 'seeing',\n",
              " 234: 'got',\n",
              " 235: 'wasted',\n",
              " 236: 'big',\n",
              " 237: 'mostly',\n",
              " 238: 'believe',\n",
              " 239: 'incredible',\n",
              " 240: 'whatever',\n",
              " 241: 'directing',\n",
              " 242: 'casting',\n",
              " 243: 'where',\n",
              " 244: 'hilarious',\n",
              " 245: 'anything',\n",
              " 246: 'top',\n",
              " 247: 'self',\n",
              " 248: 'cool',\n",
              " 249: 'gives',\n",
              " 250: 'gets',\n",
              " 251: 'classic',\n",
              " 252: 'money',\n",
              " 253: 'cheap',\n",
              " 254: 'now',\n",
              " 255: 'piece',\n",
              " 256: 'absolutely',\n",
              " 257: 'tv',\n",
              " 258: 'rent',\n",
              " 259: 'use',\n",
              " 260: 'suspense',\n",
              " 261: 'lacks',\n",
              " 262: 'lines',\n",
              " 263: 'action',\n",
              " 264: 'then',\n",
              " 265: \"wasn't\",\n",
              " 266: 'short',\n",
              " 267: 'together',\n",
              " 268: 'boring',\n",
              " 269: 'white',\n",
              " 270: 'disappointed',\n",
              " 271: 'having',\n",
              " 272: 'style',\n",
              " 273: 'myself',\n",
              " 274: 'oh',\n",
              " 275: 'pathetic',\n",
              " 276: 'long',\n",
              " 277: 'come',\n",
              " 278: 'want',\n",
              " 279: 'probably',\n",
              " 280: 'each',\n",
              " 281: 'john',\n",
              " 282: 'fine',\n",
              " 283: 'memorable',\n",
              " 284: 'avoid',\n",
              " 285: 'face',\n",
              " 286: 'superb',\n",
              " 287: 'cinema',\n",
              " 288: 'yet',\n",
              " 289: 'year',\n",
              " 290: 'joy',\n",
              " 291: 'sound',\n",
              " 292: 'comedy',\n",
              " 293: 'special',\n",
              " 294: 'effects',\n",
              " 295: 'experience',\n",
              " 296: 'recommended',\n",
              " 297: 'throughout',\n",
              " 298: 'minutes',\n",
              " 299: 'clever',\n",
              " 300: 'end',\n",
              " 301: 'period',\n",
              " 302: 'particularly',\n",
              " 303: 'tom',\n",
              " 304: 'take',\n",
              " 305: 'terrific',\n",
              " 306: 'second',\n",
              " 307: 'him',\n",
              " 308: 'fact',\n",
              " 309: 'new',\n",
              " 310: 'talk',\n",
              " 311: 'poor',\n",
              " 312: 'flick',\n",
              " 313: 'used',\n",
              " 314: 'enjoy',\n",
              " 315: 'said',\n",
              " 316: \"i'd\",\n",
              " 317: 'amazing',\n",
              " 318: 'history',\n",
              " 319: 'shot',\n",
              " 320: 'ridiculous',\n",
              " 321: 'far',\n",
              " 322: 'entire',\n",
              " 323: 'slow',\n",
              " 324: 'rather',\n",
              " 325: 'different',\n",
              " 326: 'few',\n",
              " 327: 'works',\n",
              " 328: 'almost',\n",
              " 329: 'budget',\n",
              " 330: 'own',\n",
              " 331: 'half',\n",
              " 332: 'editing',\n",
              " 333: 'especially',\n",
              " 334: 'certainly',\n",
              " 335: 'storyline',\n",
              " 336: 'single',\n",
              " 337: 'soundtrack',\n",
              " 338: 'times',\n",
              " 339: 'sometimes',\n",
              " 340: 'girl',\n",
              " 341: 'production',\n",
              " 342: 'human',\n",
              " 343: \"there's\",\n",
              " 344: 'why',\n",
              " 345: 'put',\n",
              " 346: 'lead',\n",
              " 347: 'mess',\n",
              " 348: 'place',\n",
              " 349: 'mention',\n",
              " 350: 'gave',\n",
              " 351: 'adorable',\n",
              " 352: 'without',\n",
              " 353: 'solid',\n",
              " 354: 'point',\n",
              " 355: 'hope',\n",
              " 356: 'us',\n",
              " 357: 'nice',\n",
              " 358: 'energy',\n",
              " 359: 'small',\n",
              " 360: 'become',\n",
              " 361: 'care',\n",
              " 362: 'annoying',\n",
              " 363: 'mean',\n",
              " 364: 'completely',\n",
              " 365: 'insult',\n",
              " 366: 'theater',\n",
              " 367: 'fails',\n",
              " 368: 'making',\n",
              " 369: 'indeed',\n",
              " 370: 'word',\n",
              " 371: 'cult',\n",
              " 372: 'let',\n",
              " 373: 'before',\n",
              " 374: 'everyone',\n",
              " 375: 'amount',\n",
              " 376: 'something',\n",
              " 377: 'huge',\n",
              " 378: 'pretentious',\n",
              " 379: 'during',\n",
              " 380: 'hard',\n",
              " 381: 'ray',\n",
              " 382: 'hitchcock',\n",
              " 383: 'audience',\n",
              " 384: 'extremely',\n",
              " 385: 'rest',\n",
              " 386: 'full',\n",
              " 387: 'crap',\n",
              " 388: 'depth',\n",
              " 389: 'horrible',\n",
              " 390: 'direction',\n",
              " 391: 'visual',\n",
              " 392: 'bit',\n",
              " 393: 'less',\n",
              " 394: 'performances',\n",
              " 395: 'trying',\n",
              " 396: 'guess',\n",
              " 397: 'lame',\n",
              " 398: 'started',\n",
              " 399: \"couldn't\",\n",
              " 400: 'rating',\n",
              " 401: 'three',\n",
              " 402: 'subtle',\n",
              " 403: 'young',\n",
              " 404: 'often',\n",
              " 405: 'away',\n",
              " 406: 'drago',\n",
              " 407: 'barely',\n",
              " 408: 'premise',\n",
              " 409: 'idea',\n",
              " 410: 'scamp',\n",
              " 411: 'garbage',\n",
              " 412: 'follow',\n",
              " 413: 'non',\n",
              " 414: 'keep',\n",
              " 415: 'song',\n",
              " 416: 'roles',\n",
              " 417: 'mind',\n",
              " 418: 'book',\n",
              " 419: 'mediocre',\n",
              " 420: 'itself',\n",
              " 421: 'pg',\n",
              " 422: 'strong',\n",
              " 423: 'may',\n",
              " 424: \"they're\",\n",
              " 425: 'minute',\n",
              " 426: 'around',\n",
              " 427: 'score',\n",
              " 428: 'since',\n",
              " 429: 'tale',\n",
              " 430: 'greatest',\n",
              " 431: \"won't\",\n",
              " 432: 'spoilers',\n",
              " 433: 'ed',\n",
              " 434: 'looks',\n",
              " 435: 'oscar',\n",
              " 436: 'believable',\n",
              " 437: 'actress',\n",
              " 438: 'perfect',\n",
              " 439: 'role',\n",
              " 440: 'actresses',\n",
              " 441: 'called',\n",
              " 442: 'beyond',\n",
              " 443: 'speak',\n",
              " 444: 'house',\n",
              " 445: 'shows',\n",
              " 446: 'learn',\n",
              " 447: 'embarrassing',\n",
              " 448: 'documentary',\n",
              " 449: 'appearance',\n",
              " 450: 'dvd',\n",
              " 451: \"isn't\",\n",
              " 452: 'james',\n",
              " 453: 'earlier',\n",
              " 454: 'level',\n",
              " 455: 'wish',\n",
              " 456: 'silent',\n",
              " 457: 'screenwriter',\n",
              " 458: 'torture',\n",
              " 459: 'convincing',\n",
              " 460: 'comes',\n",
              " 461: 'tell',\n",
              " 462: 'indulgent',\n",
              " 463: 'songs',\n",
              " 464: 'scared',\n",
              " 465: 'intelligence',\n",
              " 466: 'enjoyable',\n",
              " 467: 'checking',\n",
              " 468: 'looked',\n",
              " 469: 'themselves',\n",
              " 470: 'dance',\n",
              " 471: 'happen',\n",
              " 472: 'reason',\n",
              " 473: 'ranks',\n",
              " 474: 'acted',\n",
              " 475: 'overall',\n",
              " 476: 'plus',\n",
              " 477: 'footage',\n",
              " 478: 'sort',\n",
              " 479: 'conclusion',\n",
              " 480: 'ready',\n",
              " 481: 'unconvincing',\n",
              " 482: 'trash',\n",
              " 483: 'must',\n",
              " 484: 'coming',\n",
              " 485: 'heart',\n",
              " 486: 'while',\n",
              " 487: 'mickey',\n",
              " 488: 'including',\n",
              " 489: 'someone',\n",
              " 490: 'world',\n",
              " 491: 'war',\n",
              " 492: 'remember',\n",
              " 493: 'charles',\n",
              " 494: 'thriller',\n",
              " 495: 'usual',\n",
              " 496: 'living',\n",
              " 497: 'attention',\n",
              " 498: 'bore',\n",
              " 499: 'else',\n",
              " 500: 'dancing',\n",
              " 501: 'might',\n",
              " 502: 'significant',\n",
              " 503: 'aerial',\n",
              " 504: 'imagination',\n",
              " 505: 'came',\n",
              " 506: 'fans',\n",
              " 507: 'note',\n",
              " 508: 'surprisingly',\n",
              " 509: 'felt',\n",
              " 510: 'journey',\n",
              " 511: 'eyes',\n",
              " 512: 'child',\n",
              " 513: 'location',\n",
              " 514: 'thoroughly',\n",
              " 515: 'turn',\n",
              " 516: 'day',\n",
              " 517: 'memories',\n",
              " 518: 'billy',\n",
              " 519: 'possibly',\n",
              " 520: 'trilogy',\n",
              " 521: 'talented',\n",
              " 522: 'directed',\n",
              " 523: 'type',\n",
              " 524: 'low',\n",
              " 525: 'grace',\n",
              " 526: 'produced',\n",
              " 527: 'intelligent',\n",
              " 528: 'dialog',\n",
              " 529: 'decent',\n",
              " 530: 'stories',\n",
              " 531: 'unbelievable',\n",
              " 532: 'free',\n",
              " 533: 'occasionally',\n",
              " 534: 'angel',\n",
              " 535: 'parts',\n",
              " 536: 'gem',\n",
              " 537: 'yes',\n",
              " 538: 'seemed',\n",
              " 539: 'same',\n",
              " 540: 'brilliance',\n",
              " 541: 'close',\n",
              " 542: 'ups',\n",
              " 543: 'seem',\n",
              " 544: 'involved',\n",
              " 545: 'negative',\n",
              " 546: 'lovely',\n",
              " 547: 'generally',\n",
              " 548: 'meaning',\n",
              " 549: 'chemistry',\n",
              " 550: 'head',\n",
              " 551: 'serious',\n",
              " 552: 'brilliant',\n",
              " 553: 'created',\n",
              " 554: 'maybe',\n",
              " 555: 'picture',\n",
              " 556: 'values',\n",
              " 557: 'beginning',\n",
              " 558: 'star',\n",
              " 559: 'moving',\n",
              " 560: 'whatsoever',\n",
              " 561: \"i'll\",\n",
              " 562: 'plays',\n",
              " 563: 'moment',\n",
              " 564: 'emotions',\n",
              " 565: 'scenery',\n",
              " 566: 'original',\n",
              " 567: 'race',\n",
              " 568: 'paul',\n",
              " 569: 'along',\n",
              " 570: 'hours',\n",
              " 571: \"wouldn't\",\n",
              " 572: 'next',\n",
              " 573: 'finally',\n",
              " 574: 'stereotypes',\n",
              " 575: 'shots',\n",
              " 576: 'age',\n",
              " 577: 'spent',\n",
              " 578: 'children',\n",
              " 579: 'fan',\n",
              " 580: 'entertaining',\n",
              " 581: \"you'll\",\n",
              " 582: 'stage',\n",
              " 583: 'glad',\n",
              " 584: 'super',\n",
              " 585: 'hour',\n",
              " 586: 'back',\n",
              " 587: 'portrayal',\n",
              " 588: '\\x96',\n",
              " 589: 'whether',\n",
              " 590: 'graphics',\n",
              " 591: 'massive',\n",
              " 592: 'yeah',\n",
              " 593: '8',\n",
              " 594: 'consider',\n",
              " 595: 'sisters',\n",
              " 596: 'fear',\n",
              " 597: 'leave',\n",
              " 598: 'begin',\n",
              " 599: 'smart',\n",
              " 600: 'ass',\n",
              " 601: 'macbeth',\n",
              " 602: 'blood',\n",
              " 603: 'notable',\n",
              " 604: 'beautifully',\n",
              " 605: 'costumes',\n",
              " 606: 'received',\n",
              " 607: 'deserved',\n",
              " 608: 'awesome',\n",
              " 609: 'bought',\n",
              " 610: 'high',\n",
              " 611: 'photography',\n",
              " 612: 'clich√©s',\n",
              " 613: 'lazy',\n",
              " 614: 'fast',\n",
              " 615: 'idiot',\n",
              " 616: 'several',\n",
              " 617: 'final',\n",
              " 618: 'brief',\n",
              " 619: 'moral',\n",
              " 620: 'decay',\n",
              " 621: 'forces',\n",
              " 622: 'element',\n",
              " 623: 'popular',\n",
              " 624: 'reactions',\n",
              " 625: 'plenty',\n",
              " 626: 'empty',\n",
              " 627: 'hollow',\n",
              " 628: 'frankly',\n",
              " 629: 'lane',\n",
              " 630: 'disappointment',\n",
              " 631: 'proceedings',\n",
              " 632: 'features',\n",
              " 633: 'released',\n",
              " 634: 'video',\n",
              " 635: 'adaptation',\n",
              " 636: 'below',\n",
              " 637: 'turns',\n",
              " 638: 'obviously',\n",
              " 639: 'front',\n",
              " 640: 'exquisite',\n",
              " 641: 'missed',\n",
              " 642: 'step',\n",
              " 643: 'utterly',\n",
              " 644: 'today',\n",
              " 645: 'particular',\n",
              " 646: 'delivering',\n",
              " 647: 'takes',\n",
              " 648: 'fall',\n",
              " 649: 'overly',\n",
              " 650: 'supposed',\n",
              " 651: 'our',\n",
              " 652: 'offensive',\n",
              " 653: 'cartoon',\n",
              " 654: 'already',\n",
              " 655: 'form',\n",
              " 656: 'american',\n",
              " 657: 'unfunny',\n",
              " 658: 'under',\n",
              " 659: 'stars',\n",
              " 660: 'change',\n",
              " 661: 'crowd',\n",
              " 662: 'pleaser',\n",
              " 663: 'among',\n",
              " 664: 'levels',\n",
              " 665: 'italian',\n",
              " 666: 'reviewer',\n",
              " 667: 'scale',\n",
              " 668: 'course',\n",
              " 669: 'fun',\n",
              " 670: 'goes',\n",
              " 671: 'edge',\n",
              " 672: 'somewhat',\n",
              " 673: 'afraid',\n",
              " 674: 'night',\n",
              " 675: 'predictably',\n",
              " 676: 'early',\n",
              " 677: 'implausible',\n",
              " 678: 'air',\n",
              " 679: 'store',\n",
              " 680: 'began',\n",
              " 681: 'needed',\n",
              " 682: 'seriously',\n",
              " 683: 'wilkinson',\n",
              " 684: 'uplifting',\n",
              " 685: 'seems',\n",
              " 686: 'robert',\n",
              " 687: 'father',\n",
              " 688: 'although',\n",
              " 689: 'material',\n",
              " 690: 'hence',\n",
              " 691: 'machine',\n",
              " 692: 'addition',\n",
              " 693: 'mishima',\n",
              " 694: 'uninteresting',\n",
              " 695: 'chilly',\n",
              " 696: 'working',\n",
              " 697: 'singing',\n",
              " 698: 'etc',\n",
              " 699: 'pieces',\n",
              " 700: 'schrader',\n",
              " 701: 'lousy',\n",
              " 702: 'recently',\n",
              " 703: 'struck',\n",
              " 704: 'contained',\n",
              " 705: 'holes',\n",
              " 706: 'realistic',\n",
              " 707: 'lacked',\n",
              " 708: 'talent',\n",
              " 709: 'chance',\n",
              " 710: 'theme',\n",
              " 711: 'thrilled',\n",
              " 712: 'senses',\n",
              " 713: 'deeply',\n",
              " 714: 'narrative',\n",
              " 715: 'june',\n",
              " 716: 'unfortunately',\n",
              " 717: 'plain',\n",
              " 718: 'considering',\n",
              " 719: 'superbly',\n",
              " 720: 'crafted',\n",
              " 721: 'stunning',\n",
              " 722: 'fx',\n",
              " 723: 'offers',\n",
              " 724: 'parents',\n",
              " 725: 'either',\n",
              " 726: 'mexican',\n",
              " 727: 'matter',\n",
              " 728: 'noir',\n",
              " 729: 'given',\n",
              " 730: 'complex',\n",
              " 731: 'psychological',\n",
              " 732: 'soul',\n",
              " 733: 'water',\n",
              " 734: 'gripping',\n",
              " 735: 'control',\n",
              " 736: 'sure',\n",
              " 737: 'places',\n",
              " 738: 'camerawork',\n",
              " 739: \"weren't\",\n",
              " 740: 'witty',\n",
              " 741: 'above',\n",
              " 742: 'favourite',\n",
              " 743: 'directors',\n",
              " 744: 'french',\n",
              " 745: 'appealing',\n",
              " 746: 'spoiler',\n",
              " 747: 'suffering',\n",
              " 748: 'smile',\n",
              " 749: 'literally',\n",
              " 750: 'told',\n",
              " 751: '25',\n",
              " 752: 'unfolds',\n",
              " 753: 'leaves',\n",
              " 754: 'room',\n",
              " 755: 'contrast',\n",
              " 756: 'sublime',\n",
              " 757: '5',\n",
              " 758: 'poetry',\n",
              " 759: 'delivers',\n",
              " 760: 'bunch',\n",
              " 761: 'overacting',\n",
              " 762: 'space',\n",
              " 763: 'warmth',\n",
              " 764: 'reality',\n",
              " 765: 'volcano',\n",
              " 766: 'los',\n",
              " 767: 'angeles',\n",
              " 768: 'nonsense',\n",
              " 769: 'ability',\n",
              " 770: 'pull',\n",
              " 771: 'issues',\n",
              " 772: 'excellently',\n",
              " 773: 'sci',\n",
              " 774: 'perhaps',\n",
              " 775: 'turned',\n",
              " 776: 'b',\n",
              " 777: 'list',\n",
              " 778: 's',\n",
              " 779: 'girlfriend',\n",
              " 780: 'hated',\n",
              " 781: 'cost',\n",
              " 782: 'mad',\n",
              " 783: '50',\n",
              " 784: 'player',\n",
              " 785: 'loneliness',\n",
              " 786: 'underneath',\n",
              " 787: 'mouse',\n",
              " 788: 'games',\n",
              " 789: 'delight',\n",
              " 790: 'sum',\n",
              " 791: 'fantastic',\n",
              " 792: 'dogs',\n",
              " 793: 'disliked',\n",
              " 794: 'problems',\n",
              " 795: 'explanation',\n",
              " 796: 'natural',\n",
              " 797: 'describe',\n",
              " 798: 'fresh',\n",
              " 799: 'paced',\n",
              " 800: 'entirely',\n",
              " 801: 'bring',\n",
              " 802: 'occupied',\n",
              " 803: 'artist',\n",
              " 804: 'voice',\n",
              " 805: 'ratings',\n",
              " 806: 'jobs',\n",
              " 807: 'main',\n",
              " 808: 'ten',\n",
              " 809: 'charm',\n",
              " 810: 'chick',\n",
              " 811: 'case',\n",
              " 812: 'tension',\n",
              " 813: 'conflict',\n",
              " 814: 'undoubtedly',\n",
              " 815: 'running',\n",
              " 816: 'creates',\n",
              " 817: 'remake',\n",
              " 818: 'friends',\n",
              " 819: 'angles',\n",
              " 820: 'following',\n",
              " 821: 'crazy',\n",
              " 822: 'portraying',\n",
              " 823: 'alexander',\n",
              " 824: 'helps',\n",
              " 825: 'wooden',\n",
              " 826: 'light',\n",
              " 827: 'forget',\n",
              " 828: 'attempts',\n",
              " 829: 'bear',\n",
              " 830: 'thinking',\n",
              " 831: 'god',\n",
              " 832: 'male',\n",
              " 833: 'thoughts',\n",
              " 834: 'terms',\n",
              " 835: 'bold',\n",
              " 836: 'writer',\n",
              " 837: 'appalling',\n",
              " 838: 'family',\n",
              " 839: 'sets',\n",
              " 840: 'composition',\n",
              " 841: 'brian',\n",
              " 842: \"he's\",\n",
              " 843: 'kinda',\n",
              " 844: 'cute',\n",
              " 845: 'question',\n",
              " 846: 'ask',\n",
              " 847: 'terribly',\n",
              " 848: 'jamie',\n",
              " 849: 'twist',\n",
              " 850: 'shed',\n",
              " 851: 'situation',\n",
              " 852: 'aspect',\n",
              " 853: 'reading',\n",
              " 854: 'understated',\n",
              " 855: 'revealing',\n",
              " 856: \"haven't\",\n",
              " 857: 'continuity',\n",
              " 858: 'thrown',\n",
              " 859: 'directorial',\n",
              " 860: 'mother',\n",
              " 861: 'impressed',\n",
              " 862: 'death',\n",
              " 863: 'computer',\n",
              " 864: 'home',\n",
              " 865: 'true',\n",
              " 866: \"90's\",\n",
              " 867: 'cartoons',\n",
              " 868: 'humorous',\n",
              " 869: 'cause',\n",
              " 870: 'ago',\n",
              " 871: 'explain',\n",
              " 872: 'neil',\n",
              " 873: 'balance',\n",
              " 874: 'racism',\n",
              " 875: '20th',\n",
              " 876: 'knew',\n",
              " 877: 'relations',\n",
              " 878: 'last',\n",
              " 879: 'regret',\n",
              " 880: 'quinn',\n",
              " 881: 'noteworthy',\n",
              " 882: 'touching',\n",
              " 883: 'lives',\n",
              " 884: 'set',\n",
              " 885: 'episode',\n",
              " 886: '13',\n",
              " 887: 'example',\n",
              " 888: 'jimmy',\n",
              " 889: 'century',\n",
              " 890: 'surprising',\n",
              " 891: 'sand',\n",
              " 892: 'deserving',\n",
              " 893: 'heaven',\n",
              " 894: 'uses',\n",
              " 895: 'european',\n",
              " 896: 'poorly',\n",
              " 897: 'complete',\n",
              " 898: 'interested',\n",
              " 899: 'start',\n",
              " 900: 'genuine',\n",
              " 901: 'handled',\n",
              " 902: 'despite',\n",
              " 903: 'always',\n",
              " 904: 'balanced',\n",
              " 905: 'perfectly',\n",
              " 906: 'weird',\n",
              " 907: 'racial',\n",
              " 908: 'badly',\n",
              " 909: 'wind',\n",
              " 910: 'lion',\n",
              " 911: 'eye',\n",
              " 912: 'nobody',\n",
              " 913: 'cardboard',\n",
              " 914: 'frightening',\n",
              " 915: 'themes',\n",
              " 916: 'versus',\n",
              " 917: 'courtroom',\n",
              " 918: 'length',\n",
              " 919: 'disappointing',\n",
              " 920: 'freedom',\n",
              " 921: 'words',\n",
              " 922: 'central',\n",
              " 923: 'presents',\n",
              " 924: 'imaginable',\n",
              " 925: 'depicts',\n",
              " 926: 'wonder',\n",
              " 927: 'putting',\n",
              " 928: 'exceptional',\n",
              " 929: 'accused',\n",
              " 930: 'south',\n",
              " 931: 'assistant',\n",
              " 932: 'bored',\n",
              " 933: 'happened',\n",
              " 934: 'wonderfully',\n",
              " 935: 'easy',\n",
              " 936: 'lange',\n",
              " 937: 'duet',\n",
              " 938: 'appreciate',\n",
              " 939: 'quality',\n",
              " 940: 'wayne',\n",
              " 941: 'industry',\n",
              " 942: 'presence',\n",
              " 943: 'genius',\n",
              " 944: 'owned',\n",
              " 945: 'daughter',\n",
              " 946: 'provoking',\n",
              " 947: 'ruthless',\n",
              " 948: 'fat',\n",
              " 949: 'lighting',\n",
              " 950: \"joe's\",\n",
              " 951: 'charming',\n",
              " 952: 'junkyard',\n",
              " 953: 'buy',\n",
              " 954: 'female',\n",
              " 955: 'hill',\n",
              " 956: 'doctor',\n",
              " 957: 'business',\n",
              " 958: 'faux',\n",
              " 959: 'drive',\n",
              " 960: 'pure',\n",
              " 961: 'easily',\n",
              " 962: 'important',\n",
              " 963: 'fit',\n",
              " 964: 'create',\n",
              " 965: 'deserves',\n",
              " 966: 'canada',\n",
              " 967: 'sequel',\n",
              " 968: 'rated',\n",
              " 969: 'joke',\n",
              " 970: 'obvious',\n",
              " 971: 'choice',\n",
              " 972: 'lesser',\n",
              " 973: '2',\n",
              " 974: 'whiny',\n",
              " 975: 'anne',\n",
              " 976: 'honestly',\n",
              " 977: 'unpredictable',\n",
              " 978: \"aren't\",\n",
              " 979: 'fifteen',\n",
              " 980: 'pleased',\n",
              " 981: 'feel',\n",
              " 982: 'instead',\n",
              " 983: 'taking',\n",
              " 984: 'review',\n",
              " 985: 'overdue',\n",
              " 986: 'inspiration',\n",
              " 987: 'overcome',\n",
              " 988: 'rejection',\n",
              " 989: 'shelf',\n",
              " 990: 'captures',\n",
              " 991: 'essence',\n",
              " 992: 'comments',\n",
              " 993: 'wall',\n",
              " 994: 'uncalled',\n",
              " 995: 'helen',\n",
              " 996: 'baxendale',\n",
              " 997: 'credible',\n",
              " 998: 'lady',\n",
              " 999: 'cheerfull',\n",
              " 1000: 'naughty',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNYKw1qAvYns"
      },
      "source": [
        "### Vocabulary Size\n",
        "\n",
        "Number of unique/distinct words in the corpus.\n",
        "\n",
        "The index of the first word in this dictionary is 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq06PVOLLqe-"
      },
      "source": [
        "last_index_in_vocab = len(tok.index_word.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSCWyTTym0M9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62eee20e-b520-46cb-d085-7a3fedb9234a"
      },
      "source": [
        "# First word\n",
        "tok.index_word[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VBzxfsEULqfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a58e98f-12b7-4fdc-9b23-81bcfa711219"
      },
      "source": [
        "# Last word index\n",
        "last_index_in_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FABbQaWAoAlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05d68e4c-9e14-47c6-9f22-b315ad5aa18f"
      },
      "source": [
        "# Last word\n",
        "tok.index_word[last_index_in_vocab]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'passion'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFoFT94gnZKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497923b5-b5e4-4775-bdaa-c5fcec8daca7"
      },
      "source": [
        "# Total number of words in the dictionary\n",
        "vocab_size = len(tok.index_word.keys())\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iJ8vbp10oUd"
      },
      "source": [
        "### Now we can convert any arbitrary text to a sequence of integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWNPWUNL0PSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20de3856-fcbd-413e-bb44-9dc2f0fd77a2"
      },
      "source": [
        "# Words not part of the vocab will be dropped - person\n",
        "# punctuations will be dropped (the period . at the end)\n",
        "twt = tok.texts_to_sequences(['He is a lazy person.'])\n",
        "print (twt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[56, 5, 2, 613]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArCHJmtY0U_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a20f795b-f368-4990-fae1-7f64f9722984"
      },
      "source": [
        "# Words not part of the vocab will be dropped - e.g. Egyptian, Mou\n",
        "# punctuations will be dropped (the period . at the end)\n",
        "twt = tok.texts_to_sequences(['The Egyptian Mou is crazy.'])\n",
        "print (twt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5, 821]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChTGLWUf0zsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd49198-1f40-4709-869b-2b7be604359a"
      },
      "source": [
        "# punctuations will be dropped (the period . at the end)\n",
        "twt = tok.texts_to_sequences(['The movie was great.'])\n",
        "print (twt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 11, 10, 41]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VABLhJ2RvA0u"
      },
      "source": [
        "### Convert Each Review to a Sequence\n",
        "\n",
        "#### Convert the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBEb1hlrLqek"
      },
      "source": [
        "# Convert the words in a review to numeric sequences\n",
        "sequences_train = tok.texts_to_sequences(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z9EX8oVWzOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f59675-608f-43ed-f84a-077846ad321c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456    1\n",
              "231    0\n",
              "250    1\n",
              "16     1\n",
              "490    0\n",
              "      ..\n",
              "534    1\n",
              "584    1\n",
              "493    1\n",
              "527    0\n",
              "168    1\n",
              "Name: sentiment, Length: 598, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jah1Eq5MW_XJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30cc4b89-4691-4ef3-9f1a-11911049d5db"
      },
      "source": [
        "#x_train[0]\n",
        "x_train[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There still are good actors around!  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2nWfQAzxSwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de951085-a99e-41df-ca9b-56eb0804e769"
      },
      "source": [
        "# Actual review words (their numeric index in the vocab) \n",
        "# of the first review in the training set\n",
        "sequences_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 146, 21, 30, 90, 426]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcKvs-Ne4SwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fd8c29-8552-4ec8-c301-c18d0f69d454"
      },
      "source": [
        "index=0\n",
        "review = sequences_train[index]\n",
        "\n",
        "review_words =[]\n",
        "for k in review:\n",
        "  review_words.append((tok.index_word[k]))\n",
        "review_words  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['there', 'still', 'are', 'good', 'actors', 'around']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9TcDryeLeA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb27a25-0855-4462-87ca-84aea93125fd"
      },
      "source": [
        "for word in review_words:\n",
        " for key, value in tok.index_word.items():\n",
        "    if value == word:\n",
        "        print('{} - {}'.format(key,value))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34 - there\n",
            "146 - still\n",
            "21 - are\n",
            "30 - good\n",
            "90 - actors\n",
            "426 - around\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XeUg6etx6wj"
      },
      "source": [
        "#### Pad Sequences to make them the same size (40 words in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOuqpepCLqfV"
      },
      "source": [
        "sequences_matrix_train = sequence.pad_sequences(sequences_train, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akiy8gTu10vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d740500-ed9f-476d-b658-fb5faf02232e"
      },
      "source": [
        "sequences_matrix_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(598, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENuzkftWLqfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92b8aae-5867-496a-f925-313304d35e68"
      },
      "source": [
        "sequences_matrix_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,  30,  90, 426],\n",
              "       [  0,   0,   0, ...,  10, 275,  94],\n",
              "       [  0,   0,   0, ...,  18,   1,  71],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  44,  64,  84],\n",
              "       [  0,   0,   0, ..., 284, 284, 284],\n",
              "       [  0,   0,   0, ..., 383,  20, 307]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlmzTjLAXzc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f63114-3a26-4c3a-d9be-378b3c3884ae"
      },
      "source": [
        "# Check the size of each review, exactly 40 words (hopefully with zero padding at the beginning)\n",
        "print(sequences_matrix_train[0])\n",
        "\n",
        "print('\\n Every input vector is of length : ')\n",
        "print(sequences_matrix_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  34 146\n",
            "  21  30  90 426]\n",
            "\n",
            " Every input vector is of length : \n",
            "(40,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lb5fMYRxx-a"
      },
      "source": [
        "#### Convert the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh6PSUWZLqgV"
      },
      "source": [
        "# Convert to numeric sequence\n",
        "sequences_test = tok.texts_to_sequences(x_test)\n",
        "# Pad sequences\n",
        "sequences_matrix_test = sequence.pad_sequences(sequences_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWnEkUkuArL"
      },
      "source": [
        "## Build the Recurrent Net with LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CY7zbd0qWvd"
      },
      "source": [
        "### **Keras Embedding Layer**\n",
        "\n",
        "Embedding layers are almost identical to dense layers but very important to talk about as they are extensively used in preparing text input. \n",
        "An embedding layer is a dense layer without bias parameters and identity as the activation function. In fact all the layer does is a matrix multiply where the matrix entries are learnt during training. \n",
        "\n",
        "**Embedding layers are used in text processing to come up with numerical vector representations of words.**\n",
        "\n",
        "\n",
        "Keras offers an Embedding layer that can be used for neural networks on text data.\n",
        "\n",
        "It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras.\n",
        "\n",
        "**The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.**\n",
        "\n",
        "It is a flexible layer that can be used in a variety of ways, such as:\n",
        "\n",
        "i) It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
        "\n",
        "ii) It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
        "\n",
        "iii) It can be used to load a pre-trained word embedding model, a type of transfer learning.\n",
        "\n",
        "The Embedding layer is defined as the **first hidden layer of a network.**\n",
        "\n",
        "It must specify 3 arguments:\n",
        "\n",
        "**input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words. (i.e. The value of this parameter is an integer which is the Size of the vocabulary, i.e. maximum integer index + 1)\n",
        "\n",
        "**output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
        "\n",
        "**input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXMllbjPqb9Q"
      },
      "source": [
        "### Build a Custom Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqOrIlsaLqfu"
      },
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs', shape=[max_len])\n",
        "    \n",
        "    # This layer can only be used as the first layer in a model.\n",
        "    # Turns positive integers (index values) into dense vectors of fixed size.\n",
        "    # The model will take as input an integer matrix of size (batch, input_length) and the \n",
        "    # largest integer (i.e. word index) in the input should be not larger than vocabulary_size+1.  \n",
        "    # Now model's output_shape is (None, max_len, output_dim), where `None` is the batch dimension. \n",
        "    layer = Embedding(input_dim = vocab_size+1, output_dim = 500, input_length = max_len, mask_zero=True)(inputs)\n",
        "\n",
        "    # num_params = input_dim * output_dim = 2689 * 500 = 1344500  \n",
        "\n",
        "    layer = LSTM(64)(layer)   # num_params = [(num_units + input_dim + 1) * num_units] * 4\n",
        "                              # 144640 = [(64 + 500 +1) * 64] *4  \n",
        "\n",
        "    layer = Dense(256, name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1, name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs, outputs=layer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwg1Jc6puack"
      },
      "source": [
        "### Call the Custom Function to Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxekp6BkLqf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e48e35-7890-4c22-9f2c-a9f47c9e06e9"
      },
      "source": [
        "model = RNN()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 40)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 40, 500)           1344500   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,506,037\n",
            "Trainable params: 1,506,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VibkB6dLqgI"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuAMju6NuQjW"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOonQCJOLqgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4293d2e0-1858-47f4-d6bd-f53fdb075d68"
      },
      "source": [
        "model.fit(sequences_matrix_train, y_train.values, batch_size=50,epochs=50, \n",
        "          validation_data = (sequences_matrix_test, y_test.values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 289ms/step - loss: 0.6923 - accuracy: 0.5364 - val_loss: 0.6839 - val_accuracy: 0.7067\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.6645 - accuracy: 0.8101 - val_loss: 0.6173 - val_accuracy: 0.7533\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 0.4774 - accuracy: 0.9093 - val_loss: 0.5648 - val_accuracy: 0.7600\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 0.1494 - accuracy: 0.9618 - val_loss: 0.7005 - val_accuracy: 0.8000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.0462 - accuracy: 0.9944 - val_loss: 0.7265 - val_accuracy: 0.7733\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.0238 - accuracy: 0.9963 - val_loss: 0.7976 - val_accuracy: 0.7667\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.8831 - val_accuracy: 0.8000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 1.0032 - val_accuracy: 0.7800\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 124ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0523 - val_accuracy: 0.7800\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1141 - val_accuracy: 0.7800\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.7733\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.7733\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 2s 127ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.7800\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 8.2162e-04 - accuracy: 1.0000 - val_loss: 1.3019 - val_accuracy: 0.7733\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 6.2662e-04 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.7733\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 2s 126ms/step - loss: 5.6105e-04 - accuracy: 1.0000 - val_loss: 1.3574 - val_accuracy: 0.7733\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 5.1644e-04 - accuracy: 1.0000 - val_loss: 1.3861 - val_accuracy: 0.7733\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 4.2209e-04 - accuracy: 1.0000 - val_loss: 1.4234 - val_accuracy: 0.7667\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 4.9386e-04 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.7667\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 2s 135ms/step - loss: 3.7312e-04 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.7667\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 2.7668e-04 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.7667\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 3.2773e-04 - accuracy: 1.0000 - val_loss: 1.5283 - val_accuracy: 0.7667\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 2.1031e-04 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.7600\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 2s 127ms/step - loss: 1.6642e-04 - accuracy: 1.0000 - val_loss: 1.5633 - val_accuracy: 0.7600\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 1s 125ms/step - loss: 1.9077e-04 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 2.6228e-04 - accuracy: 1.0000 - val_loss: 1.5960 - val_accuracy: 0.7667\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 1.5597e-04 - accuracy: 1.0000 - val_loss: 1.6120 - val_accuracy: 0.7667\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 2s 126ms/step - loss: 1.5279e-04 - accuracy: 1.0000 - val_loss: 1.6312 - val_accuracy: 0.7667\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 2s 126ms/step - loss: 9.7730e-05 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.7667\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 1.1475e-04 - accuracy: 1.0000 - val_loss: 1.6662 - val_accuracy: 0.7667\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 8.7923e-05 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.7600\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 1.2999e-04 - accuracy: 1.0000 - val_loss: 1.7045 - val_accuracy: 0.7600\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 1.0203e-04 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.7600\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 2s 136ms/step - loss: 1.2205e-04 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.7600\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 2s 135ms/step - loss: 7.9859e-05 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7600\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 9.2309e-05 - accuracy: 1.0000 - val_loss: 1.7664 - val_accuracy: 0.7600\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 8.9512e-05 - accuracy: 1.0000 - val_loss: 1.7880 - val_accuracy: 0.7600\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 7.1113e-05 - accuracy: 1.0000 - val_loss: 1.8041 - val_accuracy: 0.7600\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 5.6402e-05 - accuracy: 1.0000 - val_loss: 1.8203 - val_accuracy: 0.7600\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 4.5271e-05 - accuracy: 1.0000 - val_loss: 1.8311 - val_accuracy: 0.7533\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 7.8888e-05 - accuracy: 1.0000 - val_loss: 1.8454 - val_accuracy: 0.7533\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 6.8856e-05 - accuracy: 1.0000 - val_loss: 1.8547 - val_accuracy: 0.7533\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 2s 128ms/step - loss: 6.8916e-05 - accuracy: 1.0000 - val_loss: 1.8685 - val_accuracy: 0.7533\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 2s 127ms/step - loss: 4.9166e-05 - accuracy: 1.0000 - val_loss: 1.8815 - val_accuracy: 0.7533\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 125ms/step - loss: 4.3111e-05 - accuracy: 1.0000 - val_loss: 1.8912 - val_accuracy: 0.7600\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 5.6556e-05 - accuracy: 1.0000 - val_loss: 1.9012 - val_accuracy: 0.7600\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 2s 127ms/step - loss: 3.9849e-05 - accuracy: 1.0000 - val_loss: 1.9107 - val_accuracy: 0.7600\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 2s 127ms/step - loss: 3.5088e-05 - accuracy: 1.0000 - val_loss: 1.9184 - val_accuracy: 0.7600\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 4.2248e-05 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.7600\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 2s 125ms/step - loss: 4.6605e-05 - accuracy: 1.0000 - val_loss: 1.9368 - val_accuracy: 0.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3328889ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBaSh2QSR3j7"
      },
      "source": [
        "If you notice the validation loss , it is actually increasing after some epochs , best model appears much earlier than 50th epoch. Therefore, we could have stopped training earlier. We can keep track of this with a Keras callback for EarlyStopping.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDCRpgmulWH"
      },
      "source": [
        "### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71j6FnJ7Lqgq"
      },
      "source": [
        "predictions = model.predict(sequences_matrix_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdgbPDGluqAw"
      },
      "source": [
        "#### Evaluate with ROC-AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COHvTi9NLqgy"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjAyZ30sLqg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db178a2-c632-4195-ea8a-aa0034974254"
      },
      "source": [
        "roc_auc_score(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.845679012345679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10eqf9nYiVt7"
      },
      "source": [
        "### Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUALQpFMiYYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fa9813-de4d-469b-959e-d0cc0c84f1d9"
      },
      "source": [
        "# Choose a review from the test set (any index number)\n",
        "index=90   # positive\n",
        "#index=20  # negative\n",
        "\n",
        "review = sequences_test[index]\n",
        "\n",
        "review_words =[]\n",
        "for k in review:\n",
        "  review_words.append((tok.index_word[k]))\n",
        "review_words  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'early',\n",
              " 'film',\n",
              " 'from',\n",
              " 'future',\n",
              " 'is',\n",
              " 'a',\n",
              " 'very',\n",
              " 'good',\n",
              " 'addition',\n",
              " 'to',\n",
              " 'the',\n",
              " 'giallo',\n",
              " 'genre']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Ak0Hq4f9Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1320fc64-3f99-4271-9b72-576add9ed319"
      },
      "source": [
        "#model.predict(sequences_matrix_test[index].reshape(1,40))\n",
        "pred = model.predict(sequences_matrix_test[index].reshape(1,40))[0][0]\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999925\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}